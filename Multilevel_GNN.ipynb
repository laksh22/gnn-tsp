{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multilevel GNN",
      "provenance": [],
      "collapsed_sections": [
        "5RLEFby6reOp",
        "0YdjC146sd8o",
        "FjjaDyRAs9eV",
        "Wqq1yyp7uS_U",
        "W2dnT40KwLpM",
        "p4_MqvHMwaZT",
        "-BgxHKvPwfrh",
        "PPgp-iQtwk0s",
        "k1oeWdJ9Go1G",
        "QH8Zr8zCGy5Q",
        "6AB2deMQwm88",
        "rbromeD3I2rQ",
        "clfIQJb3UfJ1",
        "mYfYnze3Unpy",
        "wXpeTyVCV6qS",
        "Dxsd_PmNX9nh"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zVcGNUPrRkj"
      },
      "source": [
        "# Multilevel GNN\n",
        "\n",
        "Code for FYP on _\"Efficient Graph Neural Networks for Travelling Salesman Problem using Multilevel Clustering\"_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RLEFby6reOp"
      },
      "source": [
        "## 1. Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tu3RHQ0hrOiG"
      },
      "source": [
        "# Set whether to install pyconcorde\n",
        "INSTALL_PYCONCORDE = True\n",
        "# Set whether to use CPU or GPU\n",
        "USE_GPU = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loRczOxlrhbr"
      },
      "source": [
        "if INSTALL_PYCONCORDE:\n",
        "  try: \n",
        "    from concorde.tsp import TSPSolver\n",
        "  except:\n",
        "    ! git clone https://github.com/jvkersch/pyconcorde.git\n",
        "    ! cd pyconcorde && pip install -e ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_r1X2JJrqgC"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "from torch.distributions.categorical import Categorical\n",
        "\n",
        "import datetime\n",
        "import math\n",
        "import time\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# For visualization of graphs\n",
        "%matplotlib inline\n",
        "from IPython.display import set_matplotlib_formats, clear_output\n",
        "set_matplotlib_formats('png2x','pdf')\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# For visualization of concorde\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "from scipy.spatial.distance import pdist, squareform\n",
        "\n",
        "try: \n",
        "    sys.path.append(os.path.abspath('./pyconcorde'))\n",
        "    from concorde.tsp import TSPSolver\n",
        "except:\n",
        "    print(\"PyConcorde not found\")\n",
        "\n",
        "# Reduce printed warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osYpiQhQr1F3"
      },
      "source": [
        "# Device selection\n",
        "device = torch.device(\"cpu\")\n",
        "gpu_id = -1\n",
        "\n",
        "if USE_GPU:\n",
        "  gpu_id = '0' # if single GPU is present\n",
        "  #gpu_id = '0,1,2' # if multiple GPU are present\n",
        "  os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)  \n",
        "  if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print('GPU name: {:s}, gpu_id: {:s}'.format(torch.cuda.get_device_name(0),gpu_id))   \n",
        "      \n",
        "  print(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YdjC146sd8o"
      },
      "source": [
        "## 2. Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hptb41uNsfZR"
      },
      "source": [
        "# To perform heavy-edge-matching clustering on given nodes\n",
        "def cluster_hem(nodes, device=\"cpu\"):\n",
        "  bsz, node_count, dim = nodes.size()\n",
        "  clusters = torch.zeros(bsz, node_count, device=device, dtype=torch.uint8)\n",
        "  nodes = torch.clone(nodes)\n",
        "\n",
        "  curr_idx = 0\n",
        "  for i in range(node_count//2):\n",
        "    # Find the first non-visited node\n",
        "    node_1_idx = torch.argmin(torch.isinf(nodes).long(), dim=1)[:,0]\n",
        "    node_1 = nodes[torch.arange(nodes.size(0)), node_1_idx]\n",
        "    node_1 = node_1.unsqueeze(1).expand(nodes.shape)\n",
        "\n",
        "    # Find the closest node to current\n",
        "    dist = nodes.add( - node_1).pow(2).sum(dim=2).pow(.5)\n",
        "    node_2_idx = dist.topk(2, largest=False, sorted=False)[1][torch.arange(nodes.size(0)), 1]\n",
        "\n",
        "    # Mark both as current cluster\n",
        "    clusters[torch.arange(nodes.size(0)), node_1_idx] = curr_idx\n",
        "    clusters[torch.arange(nodes.size(0)), node_2_idx] = curr_idx\n",
        "    curr_idx += 1\n",
        "\n",
        "    # Mark both nodes as visited\n",
        "    nodes[torch.arange(nodes.size(0)), node_1_idx] = float('inf')\n",
        "    nodes[torch.arange(nodes.size(0)), node_2_idx] = float('inf')\n",
        "\n",
        "  # If odd number of nodes\n",
        "  if node_count%2 != 0:\n",
        "    last_node_idx = torch.argmin(torch.isinf(nodes).long(), dim=1)[:,0]\n",
        "    clusters[torch.arange(nodes.size(0)), last_node_idx] = curr_idx\n",
        "    \n",
        "  return clusters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zU1_Q8G9srOU"
      },
      "source": [
        "# To calculate coordinates of clusters (average of members)\n",
        "def get_parent_coordinates_multilevel(graph_dataset_original, order_dataset, device=\"cpu\"):\n",
        "  graph_dataset = graph_dataset_original\n",
        "  \n",
        "  # For averaging nodes of a cluster\n",
        "  avg_pool = nn.AvgPool2d((2, 1), stride=(2, 1))\n",
        "\n",
        "  # Extracting size of each node\n",
        "  node_size = graph_dataset.size(3)\n",
        "  \n",
        "  for i in range(1, graph_dataset.size(0)):\n",
        "    # Get number of actual nodes in this level\n",
        "    level_node_count = int(graph_dataset.size(2)/(2**i))\n",
        "\n",
        "    # Average the nodes in the clusters\n",
        "    pooled_nodes = avg_pool(graph_dataset[i-1])\n",
        "\n",
        "    # Arrange nodes in order (i.e. from [0,3,2,5,3...] to [0,0,1,1,2,2...])\n",
        "    ordered_idx = order_dataset[i,:,0:level_node_count]\n",
        "    sorted_pooled_nodes = torch.gather(pooled_nodes, 1, ordered_idx.unsqueeze(2).repeat(1,1,node_size).long())\n",
        "\n",
        "    # Insert into final dataset\n",
        "    graph_dataset_clone = graph_dataset.clone() \n",
        "    graph_dataset_clone[i,:,0:sorted_pooled_nodes.size(1),:] = sorted_pooled_nodes\n",
        "    graph_dataset = graph_dataset_clone\n",
        "\n",
        "  return graph_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9JVm0D1sywK"
      },
      "source": [
        "def compute_tour_length(graphs, tours):\n",
        "  \"\"\"\n",
        "  Computes the lengths of a batch of tours\n",
        "  Inputs: \n",
        "          graphs - [batch_size, node_count, 2] Batch of TSP problem instances\n",
        "          tours  - [batch_size, node_count] Batch of sequences of node indices of TSP tours\n",
        "                                            tours[batch, time] contains the index of the node visited in given batch at given time\n",
        "  Output: \n",
        "          tour_lengths - [batch_size] Length of each TSP tour in the batch\n",
        "  \"\"\"\n",
        "  batch_size = graphs.shape[0]\n",
        "  node_count = graphs.shape[1]\n",
        "\n",
        "  indices = torch.arange(batch_size, device=graphs.device)\n",
        "  first_cities = graphs[indices, tours[:, 0], :] # [batch_size, 2]\n",
        "  previous_cities = first_cities\n",
        "  tour_lengths = torch.zeros(batch_size, device=graphs.device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for i in range(1, node_count):\n",
        "      current_cities = graphs[indices, tours[:, i], :] # [batch_size, 2]\n",
        "      tour_lengths += torch.sum((current_cities - previous_cities)**2, dim=1)**0.5\n",
        "      previous_cities = current_cities\n",
        "    tour_lengths += torch.sum((current_cities - first_cities)**2, dim=1)**0.5\n",
        "\n",
        "  return tour_lengths"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjjaDyRAs9eV"
      },
      "source": [
        "## 3. Defining model hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpqZxMWYs_n5"
      },
      "source": [
        "class DotDict(dict):\n",
        "  def __init__(self, **kwargs):\n",
        "    self.update(kwargs)\n",
        "    self.__dict__ = self\n",
        "\n",
        "args = DotDict()\n",
        "\n",
        "# Number of nodes in each input graph\n",
        "args.node_count = 16\n",
        "\n",
        "# Number of nodes in base level graph\n",
        "args.node_count_base = 2\n",
        "\n",
        "# Selecting the batch size of input graphs to model\n",
        "if args.node_count <= 50:\n",
        "  args.batch_size = 512 # TSP16 or TSP32\n",
        "else:\n",
        "  args.batch_size = 128 # TSP64 or TSP128\n",
        "\n",
        "# Selecting the size of the node embeddings\n",
        "args.embedding_size = 128\n",
        "\n",
        "# Selecting number of neurons in hidden layer of encoder\n",
        "args.ff_neurons = 512\n",
        "\n",
        "# Number of coordinates to represent a node\n",
        "args.input_node_size = 2\n",
        "\n",
        "# Layers in the base level encoder and decoder\n",
        "args.layers_encoder_base = 6\n",
        "args.layers_decoder_base = 3\n",
        "\n",
        "# Layers in all other levels' encoders and the decoders\n",
        "args.layers_encoder = 1\n",
        "args.layers_decoder = 2\n",
        "\n",
        "# Number of heads used in Multi-Headed Attention\n",
        "args.mha_heads = 8\n",
        "\n",
        "# Number of epochs to train for\n",
        "args.epochs = 100\n",
        "\n",
        "# How many batches to train in an epoch\n",
        "args.batch_per_epoch_train = 250\n",
        "\n",
        "# How many batches to evaluate in an epoch\n",
        "args.batch_per_epoch_eval = 20\n",
        "\n",
        "# ID of the GPU selected\n",
        "args.gpu_id = gpu_id\n",
        "\n",
        "# Learning rate of the model\n",
        "args.lr = 1e-9\n",
        "\n",
        "# Tolerance needed to update baseline\n",
        "args.tol = 1e-3\n",
        "\n",
        "# Should the model use batchnorm?\n",
        "args.batchnorm = True\n",
        "\n",
        "assert (args.node_count & (args.node_count-1) == 0) and args.node_count != 0 # Input graph size is power of 2\n",
        "assert (args.node_count_base & (args.node_count_base-1) == 0) and args.node_count_base != 0 # Base level graph size is power of 2\n",
        "assert args.node_count_base <= args.node_count # Base level graph can't be larger than input graph"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqvIUwPTt4AQ"
      },
      "source": [
        "# Smaller sizes for debugging\n",
        "DEBUG = False\n",
        "\n",
        "if DEBUG:\n",
        "  args.batch_per_epoch_train = 250\n",
        "  args.epochs = 100\n",
        "  args.layers_encoder = 1\n",
        "  args.layers_decoder = 2\n",
        "  args.lr = 1e-8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CluzFoIOt98X"
      },
      "source": [
        "print(args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wqq1yyp7uS_U"
      },
      "source": [
        "## 4. Generating the test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0-WyxC2uUf9"
      },
      "source": [
        "save_1000tsp = True\n",
        "\n",
        "if save_1000tsp:\n",
        "  # Generating the nodes\n",
        "  batch_size = 1000\n",
        "  generated_nodes = torch.rand(batch_size, args.node_count, args.input_node_size, device='cpu') \n",
        "\n",
        "  # Creating the directory\n",
        "  data_dir = os.path.join(\"data\")\n",
        "  if not os.path.exists(data_dir):\n",
        "    os.makedirs(data_dir)\n",
        "\n",
        "  # Saving the data\n",
        "  torch.save({ 'x': generated_nodes, }, '{}.pkl'.format(data_dir + f\"/1000tsp{args.node_count}\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvUaB35BuqEw"
      },
      "source": [
        "checkpoint = None\n",
        "\n",
        "checkpoint = torch.load(f\"data/1000tsp{args.node_count}.pkl\")\n",
        "\n",
        "if checkpoint is not None:\n",
        "  print(\"Loading...\")\n",
        "  tsp_data = checkpoint['x'].to(device)\n",
        "  tsp_data_size = tsp_data.size(1)\n",
        "  print('TSP Nodes:', tsp_data_size)\n",
        "  print(\"Loaded!\")\n",
        "else:\n",
        "  print(\"Checkpoint not found, generating...\")\n",
        "  tsp_data = torch.rand(1000, args.node_count, args.input_node_size, device=device)\n",
        "  tsp_data_size = tsp_data.size(1)\n",
        "  print('TSP Nodes:', tsp_data_size)\n",
        "  print(\"Generated!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2dnT40KwLpM"
      },
      "source": [
        "## 5. Creating the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4_MqvHMwaZT"
      },
      "source": [
        "### i. Multilevel clustering algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Plv8KNsawzwh"
      },
      "source": [
        "class Cluster(nn.Module):\n",
        "  def __init__(self, input_node_size, embedding_size):\n",
        "    super(Cluster, self).__init__()\n",
        "\n",
        "    # For averaging coordinates of neighboring nodes\n",
        "    self.avg_pool = nn.AvgPool2d((2, 1), stride=(2, 1))\n",
        "\n",
        "  def forward(self, nodes, device=\"cpu\"):\n",
        "    # Defining cluster parameters\n",
        "    batch_size, node_count, node_size = nodes.size()\n",
        "    total_levels = int(math.ceil(math.log(int(args.node_count/args.node_count_base), 2)))+1\n",
        "\n",
        "    # Placeholders for final clusters and nodes\n",
        "    graph_dataset = torch.full((total_levels, batch_size, node_count, node_size), float(\"inf\"), device=device)\n",
        "    order_dataset = torch.full((total_levels, batch_size, node_count), node_count, device=device, dtype=torch.uint8)\n",
        "    # Filled with node_count so sort operations move empty spaces to the end\n",
        "\n",
        "    # Iterate till only 2 nodes remain\n",
        "    for i in range(total_levels):\n",
        "      # Get number of actual nodes in this level\n",
        "      level_node_count = int(node_count/(2**i))\n",
        "\n",
        "      # Get nodes for current row\n",
        "      if i == 0:\n",
        "        level_nodes = nodes # Generate nodes for first row\n",
        "      else: \n",
        "        level_nodes = self.avg_pool(graph_dataset[i-1,:,:,:])[:,0:level_node_count,:] # Nodes are average of clusters from previous level\n",
        "\n",
        "      # Cluster the nodes in this level\n",
        "      clusters = cluster_hem(level_nodes, device=device)\n",
        "\n",
        "      # Arrange nodes in order (i.e. from [0,3,2,5,3...] to [0,0,1,1,2,2...])\n",
        "      sort_result = torch.sort(clusters, dim=1)\n",
        "      ordered_idx = sort_result.indices\n",
        "      sorted_nodes = torch.gather(level_nodes, 1, ordered_idx.unsqueeze(2).repeat(1,1,node_size))\n",
        "\n",
        "      # Insert into final datasets\n",
        "      graph_dataset[i,:,0:level_node_count,:] = sorted_nodes\n",
        "      order_dataset[i,:,0:level_node_count] = ordered_idx\n",
        "\n",
        "    return graph_dataset, order_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BgxHKvPwfrh"
      },
      "source": [
        "### ii. Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRj7ilqqwzdf"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "  \"\"\"\n",
        "  Inputs: \n",
        "          node_embeddings - [batch_size, node_count, embedding_size] Node embeddings after passing through FF NN\n",
        "          cluster_mappings - [log(node_count), batch_size, node_count]\n",
        "  Output: (self-transformer for encoding the set of points)\n",
        "          node_embeddings - [batch_size, node_count, embedding_size] Node embeddings after passing through FF NN\n",
        "  \"\"\"\n",
        "  def __init__(self, layers, embedding_size, mha_heads, ff_neurons, batchnorm):\n",
        "    super(Encoder, self).__init__()\n",
        "\n",
        "    assert embedding_size == mha_heads * (embedding_size//mha_heads) # Check if embedding size is divisble by number of heads\n",
        "\n",
        "    self.MHA_layers = nn.ModuleList([nn.MultiheadAttention(embedding_size, mha_heads) for _ in range(layers)])\n",
        "    self.linear1_layers = nn.ModuleList([nn.Linear(embedding_size, ff_neurons) for _ in range(layers)])\n",
        "    self.linear2_layers = nn.ModuleList([nn.Linear(ff_neurons, embedding_size) for _ in range(layers)])\n",
        "    if batchnorm:\n",
        "      self.norm1_layers = nn.ModuleList([nn.BatchNorm1d(embedding_size) for _ in range(layers)])\n",
        "      self.norm2_layers = nn.ModuleList([nn.BatchNorm1d(embedding_size) for _ in range(layers)])\n",
        "    else:\n",
        "      self.norm1_layers = nn.ModuleList([nn.LayerNorm(embedding_size) for _ in range(layers)])\n",
        "      self.norm2_layers = nn.ModuleList([nn.LayerNorm(embedding_size) for _ in range(layers)])\n",
        "\n",
        "    self.layers = layers\n",
        "    self.mha_heads = mha_heads\n",
        "\n",
        "  def forward(self, node_embeddings):\n",
        "    node_embeddings = node_embeddings.transpose(0,1)\n",
        "\n",
        "    for i in range(self.layers):\n",
        "      residual_connection = node_embeddings\n",
        "      node_embeddings, score = self.MHA_layers[i](node_embeddings, node_embeddings, node_embeddings)\n",
        "      # Adding the residual connection\n",
        "      node_embeddings = residual_connection + node_embeddings\n",
        "      node_embeddings = node_embeddings.permute(1,2,0).contiguous()\n",
        "      node_embeddings = self.norm1_layers[i](node_embeddings)\n",
        "      node_embeddings = node_embeddings.permute(2,0,1).contiguous()\n",
        "      # Feedforward\n",
        "      residual_connection = node_embeddings\n",
        "      node_embeddings = torch.relu(self.linear1_layers[i](node_embeddings))\n",
        "      node_embeddings = self.linear2_layers[i](node_embeddings)\n",
        "      node_embeddings = residual_connection + node_embeddings\n",
        "      node_embeddings = node_embeddings.permute(1,2,0).contiguous()\n",
        "      node_embeddings = self.norm2_layers[i](node_embeddings)\n",
        "      node_embeddings = node_embeddings.permute(2,0,1).contiguous()\n",
        "\n",
        "    node_embeddings = node_embeddings.transpose(0,1)\n",
        "\n",
        "    return node_embeddings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPgp-iQtwk0s"
      },
      "source": [
        "### iii. Decoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1oeWdJ9Go1G"
      },
      "source": [
        "#### a. Base level decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHogkiaswzKg"
      },
      "source": [
        "class BaseDecoder(nn.Module):\n",
        "  \"\"\"\n",
        "  Inputs: \n",
        "          Q    - [batch_size, 1, 3*embedding_size] Query vector\n",
        "          K    - [batch_size, node_count, embedding_size*layers] Key vector\n",
        "          V    - [batch_size, node_count, embedding_size*layers] Value vector\n",
        "          mask - [batch_size, node_count] For deciding which nodes to include\n",
        "  Output:\n",
        "          next_node_probabilities - [batch_size, node_count] Probabilities of which node is best for selection\n",
        "  \"\"\"\n",
        "  def __init__(self, embedding_size, mha_heads, layers):\n",
        "    super(BaseDecoder, self).__init__()\n",
        "    self.embedding_size = embedding_size\n",
        "    self.mha_heads = mha_heads\n",
        "    self.layers = layers\n",
        "    self.WO = nn.ModuleList([nn.Linear(embedding_size, embedding_size) for _ in range(layers-1)])\n",
        "\n",
        "  def MHA(self, Q, K, V, mha_heads, mask=None, clip_value=None):\n",
        "    batch_size, node_count, embedding_size = K.size() # Get the dimensions of the key\n",
        "    \n",
        "    # Reshape Q, K, and V for MHA\n",
        "    if mha_heads > 1:\n",
        "      Q = Q.transpose(1,2).contiguous()\n",
        "      Q = Q.view(batch_size * mha_heads, embedding_size//mha_heads, 1)\n",
        "      Q = Q.transpose(1,2).contiguous()\n",
        "\n",
        "      K = K.transpose(1,2).contiguous()\n",
        "      K = K.view(batch_size * mha_heads, embedding_size//mha_heads, node_count)\n",
        "      K = K.transpose(1,2).contiguous()\n",
        "\n",
        "      V = V.transpose(1,2).contiguous()\n",
        "      V = V.view(batch_size * mha_heads, embedding_size//mha_heads, node_count)\n",
        "      V = V.transpose(1,2).contiguous()\n",
        "\n",
        "    # Multiply Q and K to get attention weights\n",
        "    attention_weights = torch.bmm(Q, K.transpose(1,2)) / Q.size(-1)**0.5\n",
        "      \n",
        "    # Clip attention weights between [-C, C]\n",
        "    if clip_value is not None:\n",
        "      attention_weights = clip_value * torch.tanh(attention_weights)\n",
        "\n",
        "    # Mask already visited nodes\n",
        "    if mask is not None:\n",
        "      if mha_heads > 1:\n",
        "        mask = torch.repeat_interleave(mask, repeats=mha_heads, dim=0)\n",
        "      attention_weights = attention_weights.masked_fill(mask.unsqueeze(1), float('-inf'))\n",
        "\n",
        "    # Get softmax of attention weights\n",
        "    attention_weights = torch.softmax(attention_weights, dim=-1)\n",
        "\n",
        "    # Get decoder output\n",
        "    attention_output = torch.bmm(attention_weights, V)\n",
        "\n",
        "    # Reshape and get mean if MHA is used\n",
        "    if mha_heads > 1:\n",
        "      attention_output = attention_output.transpose(1, 2).contiguous()\n",
        "      attention_output = attention_output.view(batch_size, embedding_size, 1)\n",
        "      attention_output = attention_output.transpose(1, 2).contiguous()\n",
        "      attention_weights = attention_weights.view(batch_size, mha_heads, 1, node_count)\n",
        "      attention_weights = attention_weights.mean(dim=1) # Take mean across heads\n",
        "\n",
        "    return attention_output, attention_weights\n",
        "\n",
        "  def forward(self, Q, K, V, mask=None):\n",
        "\n",
        "    for i in range(self.layers):\n",
        "      Ki = K[:,:,i * self.embedding_size : (i+1) * self.embedding_size].contiguous()\n",
        "      Vi = V[:,:,i * self.embedding_size : (i+1) * self.embedding_size].contiguous()\n",
        "      if i < self.layers-1: # Use MHA\n",
        "        residual_Q = Q\n",
        "        attention_output, _ = self.MHA(Q, Ki, Vi, self.mha_heads, mask)\n",
        "        Q = self.WO[i](attention_output) # MHA output\n",
        "        Q = residual_Q + torch.relu(Q)\n",
        "      else: # Use single head for last layer\n",
        "        _, attention_weights = self.MHA(Q, Ki, Vi, 1, mask, 10)\n",
        "    next_node_probabilities = attention_weights.squeeze()\n",
        "\n",
        "    return next_node_probabilities"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QH8Zr8zCGy5Q"
      },
      "source": [
        "#### b. Multilevel decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqIIw7H8G19W"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "  \"\"\"\n",
        "  Inputs: \n",
        "          Q    - [batch_size, 1, 3*embedding_size] Query vector\n",
        "          K    - [batch_size, node_count, embedding_size*layers] Key vector\n",
        "          V    - [batch_size, node_count, embedding_size*layers] Value vector\n",
        "          to_visit - [batch_size, 2] Neighbouring nodes to be visited next\n",
        "  Output:\n",
        "          next_node_probabilities - [batch_size, 2] Probabilities of which node is best for selection\n",
        "  \"\"\"\n",
        "  def __init__(self, embedding_size, mha_heads, layers):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.embedding_size = embedding_size\n",
        "    self.mha_heads = mha_heads\n",
        "    self.layers = layers\n",
        "    self.WO = nn.ModuleList([nn.Linear(embedding_size, embedding_size) for _ in range(layers-1)])\n",
        "\n",
        "  def MHA(self, Q, K, V, mha_heads, clip_value=None):\n",
        "    batch_size, node_count, embedding_size = K.size() # Get the dimensions of the key\n",
        "    \n",
        "    # Reshape Q, K, and V for MHA\n",
        "    if mha_heads > 1:\n",
        "      Q = Q.transpose(1,2).contiguous()\n",
        "      Q = Q.view(batch_size * mha_heads, embedding_size//mha_heads, 1)\n",
        "      Q = Q.transpose(1,2).contiguous()\n",
        "\n",
        "      K = K.transpose(1,2).contiguous()\n",
        "      K = K.view(batch_size * mha_heads, embedding_size//mha_heads, node_count)\n",
        "      K = K.transpose(1,2).contiguous()\n",
        "\n",
        "      V = V.transpose(1,2).contiguous()\n",
        "      V = V.view(batch_size * mha_heads, embedding_size//mha_heads, node_count)\n",
        "      V = V.transpose(1,2).contiguous()\n",
        "\n",
        "    # Multiply Q and K to get attention weights\n",
        "    attention_weights = torch.bmm(Q, K.transpose(1,2)) / Q.size(-1)**0.5\n",
        "      \n",
        "    # Clip attention weights between [-C, C]\n",
        "    if clip_value is not None:\n",
        "      attention_weights = clip_value * torch.tanh(attention_weights)\n",
        "\n",
        "    # Get softmax of attention weights\n",
        "    attention_weights = torch.softmax(attention_weights, dim=-1)\n",
        "\n",
        "    # Get decoder output\n",
        "    attention_output = torch.bmm(attention_weights, V)\n",
        "\n",
        "    # Reshape and get mean if MHA is used\n",
        "    if mha_heads > 1:\n",
        "      attention_output = attention_output.transpose(1, 2).contiguous()\n",
        "      attention_output = attention_output.view(batch_size, embedding_size, 1)\n",
        "      attention_output = attention_output.transpose(1, 2).contiguous()\n",
        "      attention_weights = attention_weights.view(batch_size, mha_heads, 1, node_count)\n",
        "      attention_weights = attention_weights.mean(dim=1) # Take mean across heads\n",
        "\n",
        "    return attention_output, attention_weights\n",
        "\n",
        "  def forward(self, Q, K, V, to_visit=None):\n",
        "    bsz, nc, ns = K.size()\n",
        "\n",
        "    K = torch.gather(K, 1, to_visit.unsqueeze(2).repeat(1,1,K.size(2)))\n",
        "    V = torch.gather(V, 1, to_visit.unsqueeze(2).repeat(1,1,V.size(2)))\n",
        "\n",
        "    for i in range(self.layers):\n",
        "      Ki = K[:,:,i * self.embedding_size : (i+1) * self.embedding_size].contiguous()\n",
        "      Vi = V[:,:,i * self.embedding_size : (i+1) * self.embedding_size].contiguous()\n",
        "      if i < self.layers-1: # Use MHA\n",
        "        residual_Q = Q\n",
        "        attention_output, _ = self.MHA(Q, Ki, Vi, self.mha_heads)\n",
        "        Q = self.WO[i](attention_output) # MHA output\n",
        "        Q = residual_Q + torch.relu(Q)\n",
        "      else: # Use single head for last layer\n",
        "        _, attention_weights = self.MHA(Q, Ki, Vi, 1, 10)\n",
        "    next_node_probabilities = attention_weights.squeeze()\n",
        "\n",
        "    output = torch.zeros((bsz, nc), device=device)\n",
        "    output[torch.arange(bsz), to_visit[:,0]] = next_node_probabilities[torch.arange(bsz),0]\n",
        "    output[torch.arange(bsz), to_visit[:,1]] = next_node_probabilities[torch.arange(bsz),1]\n",
        "\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AB2deMQwm88"
      },
      "source": [
        "### iv. Multilevel Graph Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wb08VxaHu9mD"
      },
      "source": [
        "class MGNN(nn.Module):\n",
        "  def __init__(self, input_node_size, embedding_size, ff_neurons, \n",
        "               layers_encoder, layers_encoder_base,\n",
        "               layers_decoder, layers_decoder_base,\n",
        "               mha_heads, cluster_levels, batchnorm=True):\n",
        "    super(MGNN, self).__init__()\n",
        "\n",
        "    # Embed nodes into higher dimension\n",
        "    self.input_embeddings = nn.Linear(input_node_size, embedding_size)\n",
        "\n",
        "    # Cluster nodes for multiple levels\n",
        "    self.clustering = Cluster(input_node_size, embedding_size)\n",
        "\n",
        "    # Encoder layers\n",
        "    self.encoder_base = Encoder(layers_encoder_base, embedding_size, mha_heads, ff_neurons, batchnorm)\n",
        "    self.encoder = Encoder(layers_encoder, embedding_size, mha_heads, ff_neurons, batchnorm)\n",
        "\n",
        "    # Query dimensionality projector\n",
        "    self.query_projecter = nn.Linear(3*embedding_size, embedding_size)\n",
        "    self.embedding_size = embedding_size\n",
        "\n",
        "    # Embeddings of the first node of the tour and the current node\n",
        "    self.place_holder_start = nn.Parameter(torch.randn(embedding_size))\n",
        "    self.place_holder_now = nn.Parameter(torch.randn(embedding_size))\n",
        "\n",
        "    # Decoder layers\n",
        "    self.decoder_base = BaseDecoder(embedding_size, mha_heads, layers_decoder_base)\n",
        "    self.WK_decoder_base = nn.Linear(embedding_size, layers_decoder_base * embedding_size)\n",
        "    self.WV_decoder_base = nn.Linear(embedding_size, layers_decoder_base * embedding_size)\n",
        "\n",
        "    self.decoders = nn.ModuleList([Decoder(embedding_size, mha_heads, layers_decoder) for _ in range(cluster_levels)])\n",
        "    self.WK_decoder = nn.Linear(embedding_size, layers_decoder * embedding_size)\n",
        "    self.WV_decoder = nn.Linear(embedding_size, layers_decoder * embedding_size)\n",
        "\n",
        "  def forward(self, nodes, deterministic=False):\n",
        "    # Sort the nodes along the X-axis\n",
        "    _, sort_indices = torch.sort(nodes[:,:,0], dim=1)\n",
        "    nodes = torch.gather(nodes, 1, sort_indices.unsqueeze(2).repeat(1,1,args.input_node_size))\n",
        "\n",
        "    # Cluster the nodes\n",
        "    graph_dataset, order_dataset = self.clustering(nodes, device)\n",
        "\n",
        "    # Extract parameters from graph\n",
        "    cluster_levels, batch_size, node_count, _ = graph_dataset.size()\n",
        "    zero_to_batch_size = torch.arange(batch_size, device=device) # [0,1,...,batch_size-1]\n",
        "\n",
        "    # Convert nodes to higher dimensionality\n",
        "    h = self.input_embeddings(graph_dataset[0,:,:,:])\n",
        "\n",
        "    # Encode the nodes and get level-by-level cluster coordinates (for 0...M-1)\n",
        "    embedded_graph_dataset = torch.full((math.ceil(math.log(node_count, 2)), batch_size, node_count, args.embedding_size), float(\"inf\"), device=device)\n",
        "    embedded_graph_dataset[0,:,:,:] = self.encoder(h)\n",
        "    h_levels_encoded = get_parent_coordinates_multilevel(embedded_graph_dataset, order_dataset, device)\n",
        "    h_graph_encoded = embedded_graph_dataset[0,:,:,:].mean(dim=1) # Get the graph embedding as well\n",
        "    \n",
        "    # Encode the nodes and get level-by-level cluster coordinates (for M)\n",
        "    embedded_graph_dataset_base = torch.full((math.ceil(math.log(node_count, 2)), batch_size, node_count, args.embedding_size), float(\"inf\"), device=device)\n",
        "    embedded_graph_dataset_base[0,:,:,:] = self.encoder_base(h)\n",
        "    h_levels_encoded_base = get_parent_coordinates_multilevel(embedded_graph_dataset_base, order_dataset, device)\n",
        "    h_graph_encoded_base = embedded_graph_dataset_base[0,:,:,:].mean(dim=1) # Get the graph embedding as well\n",
        "\n",
        "    # For storing final -ve probs of choices made in each time step of the main graph\n",
        "    log_prob_actions_sum_final = torch.zeros(batch_size, device=device)\n",
        "    # For storing final -ve probs of choices made in each time step of the main graph\n",
        "    log_prob_actions_sum_base = torch.zeros(batch_size, device=device)\n",
        "\n",
        "    # Create list for mask of visited cities\n",
        "    mask_visited_nodes = torch.zeros(batch_size, args.node_count_base, device=device).bool()\n",
        "\n",
        "    # Iterate through each level of clustering, starting from coarsest graph\n",
        "    base_level = cluster_levels-1\n",
        "    for i in range(base_level, -1, -1):\n",
        "      if i == base_level:\n",
        "        # Extract parameters from current level\n",
        "        node_count = int(graph_dataset.size(2)/(2**i))\n",
        "        iterations = node_count\n",
        "        nodes_added = 0\n",
        "\n",
        "        # Get current level\n",
        "        h_encoded = h_levels_encoded_base[i,:,0:node_count,:]\n",
        "\n",
        "        # Create list for storing probs of the choices made at each time step\n",
        "        log_prob_actions_sum = torch.zeros(batch_size, node_count, device=device)\n",
        "\n",
        "        # Create list for storing tours for the batch\n",
        "        tours = torch.zeros(batch_size, node_count, device=device)\n",
        "\n",
        "        # Create initial key and value for the decoder\n",
        "        K_encoded = self.WK_decoder_base(h_encoded)\n",
        "        V_encoded = self.WV_decoder_base(h_encoded)\n",
        "\n",
        "        # Store the start and current nodes of the tour\n",
        "        h_start = self.place_holder_start.view(1, self.embedding_size).expand_as(h_graph_encoded_base)\n",
        "        h_now = self.place_holder_now.view(1, self.embedding_size).expand_as(h_graph_encoded_base)\n",
        "\n",
        "        # Construct the tour recursively\n",
        "        for t in range(iterations):\n",
        "          # Compute probability over the next node in the tour\n",
        "          query = torch.cat((h_graph_encoded_base, h_start, h_now), dim=-1).unsqueeze(1)\n",
        "          query = self.query_projecter(query)\n",
        "          prob_next_node = self.decoder_base(query, K_encoded, V_encoded, mask_visited_nodes)\n",
        "\n",
        "          if deterministic:\n",
        "            index = torch.argmax(prob_next_node, dim=1)\n",
        "          else:\n",
        "            index = Categorical(prob_next_node).sample()\n",
        "\n",
        "          # Compute log of probabilities of the action items\n",
        "          prob_of_choices = prob_next_node[zero_to_batch_size, index]\n",
        "          log_prob_actions_sum[:, nodes_added] = torch.log(prob_of_choices)\n",
        "          \n",
        "          # Update tour\n",
        "          tours[:, nodes_added] = index\n",
        "          nodes_added += 1\n",
        "\n",
        "          # Update current node\n",
        "          h_now = h_encoded[zero_to_batch_size, index, :]\n",
        "          if t == 0: # Embedding of first node of tour\n",
        "            h_start = h_now\n",
        "\n",
        "          # Update mask of visited nodes\n",
        "          mask_visited_nodes = mask_visited_nodes.clone()\n",
        "          mask_visited_nodes[zero_to_batch_size, index] = True\n",
        "      else:\n",
        "        # Extract parameters from current level\n",
        "        node_count = int(graph_dataset.size(2)/(2**i))\n",
        "        iterations = int(node_count/2)\n",
        "        nodes_added = 0\n",
        "\n",
        "        # Get current level\n",
        "        h_encoded = h_levels_encoded[i,:,0:node_count,:]\n",
        "\n",
        "        # Create list for storing probs of the choices made at each time step\n",
        "        log_prob_actions_sum = torch.zeros(batch_size, node_count, device=device)\n",
        "\n",
        "        # To store nodes to be visited next, starting from 0,1\n",
        "        next_neighbors = torch.arange(2, device=device).unsqueeze(0).repeat(batch_size,1).long()\n",
        "\n",
        "        # Create list for storing tours for the batch\n",
        "        tours = torch.zeros(batch_size, node_count, device=device)\n",
        "\n",
        "        # Create initial key and value for the decoder\n",
        "        K_encoded = self.WK_decoder(h_encoded)\n",
        "        V_encoded = self.WV_decoder(h_encoded)\n",
        "\n",
        "        # Store the start and current nodes of the tour\n",
        "        h_start = self.place_holder_start.view(1, self.embedding_size).expand_as(h_graph_encoded)\n",
        "        h_now = self.place_holder_now.view(1, self.embedding_size).expand_as(h_graph_encoded)\n",
        "\n",
        "        # Construct the tour recursively\n",
        "        for t in range(iterations):\n",
        "          # Compute probability over the next node in the tour\n",
        "          query = torch.cat((h_graph_encoded, h_start, h_now), dim=-1).unsqueeze(1)\n",
        "          query = self.query_projecter(query)\n",
        "          prob_next_node = self.decoders[i](query, K_encoded, V_encoded, next_neighbors)\n",
        "\n",
        "          if deterministic:\n",
        "            index = torch.argmax(prob_next_node, dim=1)\n",
        "          else:\n",
        "            index = Categorical(prob_next_node).sample()\n",
        "\n",
        "          # Get cluster ID of the current node\n",
        "          cluster_id = index//2\n",
        "\n",
        "          # If sibling exists, add to tour and mask\n",
        "          neighbors = torch.stack((2*cluster_id, 2*cluster_id+1), dim=1).long()\n",
        "          neighbor_idx = torch.where(torch.flatten(neighbors[:,0])==index,1,0)\n",
        "\n",
        "          first_child = index\n",
        "          second_child = torch.gather(neighbors, 1, neighbor_idx.unsqueeze(1)).flatten()\n",
        "\n",
        "          # Compute log of probabilities of the action items\n",
        "          prob_of_choices = prob_next_node[zero_to_batch_size, first_child]\n",
        "          log_prob_actions_sum[:, nodes_added] = torch.log(prob_of_choices)\n",
        "\n",
        "          # Compute log of probabilities of the siblings of those selected\n",
        "          prob_of_choices = prob_next_node[zero_to_batch_size, second_child]\n",
        "          log_prob_actions_sum[:, nodes_added+1] = torch.log(prob_of_choices)\n",
        "\n",
        "          # Update current node\n",
        "          h_now = h_encoded[zero_to_batch_size, second_child, :]\n",
        "          if t == 0: # Embedding of first node of tour\n",
        "            h_start = h_encoded[zero_to_batch_size, first_child, :]\n",
        "          \n",
        "          # Update tour\n",
        "          tours[:, nodes_added] = first_child\n",
        "          tours[:, nodes_added+1] = second_child\n",
        "          nodes_added += 2\n",
        "\n",
        "          # Extract index of current cluster from parent tour\n",
        "          parent_cluster_id = torch.argmax(torch.where(order_dataset[i+1,:,0:int(node_count/2)] == cluster_id.unsqueeze(1), 1, 0), dim=1).unsqueeze(1).repeat(1,int(node_count/2))\n",
        "          parent_cluster_pos = torch.argmax(torch.where(parent_tours == parent_cluster_id, 1, 0), dim=1)\n",
        "\n",
        "          # Get the cluster ID of the children of the next cluster in parent tour\n",
        "          next_cluster_pos = (parent_cluster_pos+1)%parent_tours.size(1)\n",
        "          next_parent_cluster_id = torch.gather(parent_tours, 1, next_cluster_pos.unsqueeze(1)).long()\n",
        "          next_cluster_id = order_dataset[i+1,zero_to_batch_size,next_parent_cluster_id.squeeze()]\n",
        "\n",
        "          # Get 2 nodes in current level belonging to next cluster\n",
        "          next_neighbors = torch.stack((2*next_cluster_id, 2*next_cluster_id+1), dim=1).long()\n",
        "\n",
        "          # Mark clusters to be visited next as True\n",
        "          neighbors_mask = torch.zeros(batch_size, node_count, device=device, dtype=torch.bool)\n",
        "          neighbors_mask[zero_to_batch_size, next_neighbors[zero_to_batch_size,0]] = True\n",
        "          neighbors_mask[zero_to_batch_size, next_neighbors[zero_to_batch_size,1]] = True\n",
        "\n",
        "      parent_tours = tours\n",
        "      if i == 0:\n",
        "        log_prob_actions_sum_final =  log_prob_actions_sum.sum(dim=1)\n",
        "      if i == base_level:\n",
        "        log_prob_actions_sum_base = log_prob_actions_sum.sum(dim=1)\n",
        "        tours_base = tours\n",
        "\n",
        "    # Creating final variables to be returned\n",
        "    sorted_graph = graph_dataset[0]\n",
        "    sorted_graph_base = graph_dataset[base_level,:,0:args.node_count_base]\n",
        "    tours = tours.long()\n",
        "    tours_base = tours_base.long()\n",
        "\n",
        "    return (sorted_graph, \n",
        "          sorted_graph_base, \n",
        "          tours, \n",
        "          tours_base, \n",
        "          log_prob_actions_sum_final,\n",
        "          log_prob_actions_sum_base)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbromeD3I2rQ"
      },
      "source": [
        "## 6. Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FshXskNVI7PK"
      },
      "source": [
        "try:\n",
        "  del model_train\n",
        "  del model_baseline\n",
        "except:\n",
        "  pass\n",
        "\n",
        "# Use more than 1 GPU if available\n",
        "if torch.cuda.device_count() > 1:\n",
        "  print(f\"Using {torch.cuda.device_count()} GPUs...\")\n",
        "  model_train = nn.DataParallel(model_train)\n",
        "  model_baseline = nn.DataParallel(model_baseline)\n",
        "\n",
        "\n",
        "# Setting up the model to be trained\n",
        "model_train = MGNN(args.input_node_size, args.embedding_size, args.ff_neurons,\n",
        "                  args.layers_encoder, args.layers_encoder_base,\n",
        "                  args.layers_decoder, args.layers_decoder_base,\n",
        "                  args.mha_heads, int(args.node_count/args.node_count_base), batchnorm=args.batchnorm)\n",
        "model_train = model_train.to(device)\n",
        "\n",
        "# Setting up the baseline model\n",
        "model_baseline = MGNN(args.input_node_size, args.embedding_size, args.ff_neurons,\n",
        "                  args.layers_encoder, args.layers_encoder_base,\n",
        "                  args.layers_decoder, args.layers_decoder_base,\n",
        "                  args.mha_heads, int(args.node_count/args.node_count_base), batchnorm=args.batchnorm)\n",
        "model_baseline = model_baseline.to(device)\n",
        "model_baseline.eval()\n",
        "\n",
        "# Create the Adam optimizer\n",
        "optimizer = torch.optim.Adam(model_train.parameters(), lr = args.lr)\n",
        "\n",
        "print(args)\n",
        "\n",
        "# Training logs\n",
        "os.system(\"mkdir logs\")\n",
        "time_stamp = datetime.datetime.now().strftime(\"%y-%m-%d--%H-%M-%S\")\n",
        "file_name = \"logs\" + \"/\" + time_stamp + \"-n{}\".format(args.node_count) + \"-gpu{}\".format(args.gpu_id) + \".txt\"\n",
        "file = open(file_name, \"w\", 1)\n",
        "file.write(time_stamp + \"\\n\\n\")\n",
        "for arg in vars(args):\n",
        "  file.write(arg)\n",
        "  hyper_param_val = \"={}\".format(getattr(args, arg))\n",
        "  file.write(hyper_param_val)\n",
        "  file.write(\"\\n\")\n",
        "file.write(\"\\n\\n\")\n",
        "\n",
        "# For tracking the train and baseline tour lengths\n",
        "plot_performance_train = []\n",
        "plot_performance_baseline = []\n",
        "\n",
        "# Main training loop\n",
        "for epoch in range(0, args.epochs):\n",
        "  #############################\n",
        "  # TRAIN MODEL FOR ONE EPOCH #\n",
        "  #############################\n",
        "  start = time.time()\n",
        "  model_train.train()\n",
        "\n",
        "  for step in range(1, args.batch_per_epoch_train+1):\n",
        "    # Generate a batch of TSP instances\n",
        "    nodes = torch.rand(args.batch_size, args.node_count, args.input_node_size, device=device)\n",
        "\n",
        "    # Compute the tours for the model\n",
        "    (sorted_nodes_train, \n",
        "    sorted_nodes_train_base, \n",
        "    tours_train, \n",
        "    tours_train_base,\n",
        "    log_prob_actions_sum_final,\n",
        "    log_prob_actions_sum_base) = model_train(nodes, deterministic=False)\n",
        "\n",
        "    # Compute the tours for the baseline\n",
        "    with torch.no_grad():\n",
        "      (sorted_nodes_baseline, \n",
        "      sorted_nodes_baseline_base, \n",
        "      tours_baseline, \n",
        "      tours_baseline_base,\n",
        "      _, _) = model_train(nodes, deterministic=True)\n",
        "\n",
        "    # Get the lengths of the tours\n",
        "    train_length = compute_tour_length(sorted_nodes_train, tours_train)\n",
        "    baseline_length = compute_tour_length(sorted_nodes_baseline, tours_baseline)\n",
        "    train_length_base = compute_tour_length(sorted_nodes_train_base, tours_train_base)\n",
        "    baseline_length_base = compute_tour_length(sorted_nodes_baseline_base, tours_baseline_base)\n",
        "\n",
        "    # Backpropogation\n",
        "    loss_final = torch.mean((train_length - baseline_length) * log_prob_actions_sum_final)\n",
        "    loss_base = torch.mean((train_length_base - baseline_length_base) * log_prob_actions_sum_base)\n",
        "    loss = loss_final + loss_base\n",
        "           \n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  \n",
        "  epoch_time = time.time() - start\n",
        "\n",
        "  ###############################\n",
        "  # EVALUATE MODEL AND BASELINE #\n",
        "  ###############################\n",
        "  model_train.eval()\n",
        "  mean_tour_length_train = 0\n",
        "  mean_tour_length_baseline = 0\n",
        "\n",
        "  for step in range(0, args.batch_per_epoch_eval):\n",
        "    # Generate a batch of TSP instances\n",
        "    nodes = torch.rand(args.batch_size, args.node_count, args.input_node_size, device=device)\n",
        "\n",
        "    # Compute the tours of the model and the baseline\n",
        "    with torch.no_grad():\n",
        "      sorted_nodes_train, _, tours_train, _, _, _ = model_train(nodes, deterministic=True)\n",
        "      sorted_nodes_baseline, _, tours_baseline, _, _, _ = model_baseline(nodes, deterministic=True)\n",
        "\n",
        "    # Get the lengths of the tours\n",
        "    train_length = compute_tour_length(sorted_nodes_train, tours_train)\n",
        "    baseline_length = compute_tour_length(sorted_nodes_baseline, tours_baseline)\n",
        "\n",
        "    # Add tour length\n",
        "    mean_tour_length_train += train_length.mean().item()\n",
        "    mean_tour_length_baseline += baseline_length.mean().item()\n",
        "\n",
        "  # Compute mean of tour lengths across batches\n",
        "  mean_tour_length_train =  mean_tour_length_train / args.batch_per_epoch_eval\n",
        "  mean_tour_length_baseline =  mean_tour_length_baseline / args.batch_per_epoch_eval\n",
        "\n",
        "  # Update baseline if new length is lower than baseline\n",
        "  update_baseline = mean_tour_length_train + args.tol < mean_tour_length_baseline\n",
        "  if update_baseline:\n",
        "    model_baseline.load_state_dict(model_train.state_dict())\n",
        "\n",
        "  # Compute TSP tours for the test set\n",
        "  with torch.no_grad():\n",
        "    sorted_tsp_data, _, tours_baseline, _, _, _ = model_baseline(tsp_data, deterministic=True)\n",
        "  mean_tour_length_test = compute_tour_length(sorted_tsp_data, tours_baseline).mean().item()\n",
        "\n",
        "  # Storing the training and baseline tour lengths\n",
        "  plot_performance_train.append([(epoch+1), mean_tour_length_train])\n",
        "  plot_performance_baseline.append([(epoch+1), mean_tour_length_baseline])\n",
        "\n",
        "  # Log epoch details\n",
        "  epoch_details = 'Epoch: {:d}, Epoch Time: {:.3f}min, Train Length: {:.3f}, Baseline Length: {:.3f}, Test Length: {:.3f}, Baseline Updated: {}'.format(\n",
        "      epoch, epoch_time/60, mean_tour_length_train, mean_tour_length_baseline, mean_tour_length_test, update_baseline) \n",
        "  print(epoch_details)\n",
        "  file.write(epoch_details + '\\n')\n",
        "\n",
        "  # Save checkpoints\n",
        "  checkpoint_dir = os.path.join(\"checkpoint\")\n",
        "  if not os.path.exists(checkpoint_dir):\n",
        "    os.makedirs(checkpoint_dir)\n",
        "  torch.save({\n",
        "      'epoch': epoch,\n",
        "      'time': epoch_time,\n",
        "      'loss': loss.item(),\n",
        "      'TSP_length': [torch.mean(train_length).item(), torch.mean(baseline_length).item()],\n",
        "      'plot_performance_train': plot_performance_train,\n",
        "      'plot_performance_baseline': plot_performance_baseline,\n",
        "      'mean_tour_length_test': mean_tour_length_test,\n",
        "      'model_baseline': model_baseline.state_dict(),\n",
        "      'model_train': model_train.state_dict(),\n",
        "      'optimizer': optimizer.state_dict(),\n",
        "  }, '{}.pkl'.format(checkpoint_dir + \"/checkpoint\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clfIQJb3UfJ1"
      },
      "source": [
        "## 7. Plotting the results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYfYnze3Unpy"
      },
      "source": [
        "### i. Load from checkpoints (if needed)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__73FtupLaLR"
      },
      "source": [
        "LOAD = True\n",
        "if LOAD:\n",
        "  model_train = MGNN(args.input_node_size, args.embedding_size, args.ff_neurons,\n",
        "                  args.layers_encoder, args.layers_encoder_base,\n",
        "                  args.layers_decoder, args.layers_decoder_base,\n",
        "                  args.mha_heads, int(args.node_count/args.node_count_base), batchnorm=args.batchnorm)\n",
        "  model_train = model_train.to(device)\n",
        "\n",
        "  model_baseline = MGNN(args.input_node_size, args.embedding_size, args.ff_neurons,\n",
        "                    args.layers_encoder, args.layers_encoder_base,\n",
        "                    args.layers_decoder, args.layers_decoder_base,\n",
        "                    args.mha_heads, int(args.node_count/args.node_count_base), batchnorm=args.batchnorm)\n",
        "\n",
        "  optimizer = torch.optim.Adam(model_train.parameters(), lr=args.lr) \n",
        "\n",
        "  checkpoint = torch.load(\"./checkpoint/checkpoint.pkl\", map_location=torch.device('cpu'))\n",
        "  epoch_ckpt = checkpoint['epoch']\n",
        "  time_ckpt = checkpoint['time']\n",
        "  loss_ckpt = checkpoint['loss']\n",
        "  TSP_length_ckpt = checkpoint['TSP_length']\n",
        "  plot_performance_train_ckpt = checkpoint['plot_performance_train']\n",
        "  plot_performance_baseline_ckpt = checkpoint['plot_performance_baseline']\n",
        "  mean_tour_length_test = checkpoint['mean_tour_length_test']\n",
        "  model_baseline.load_state_dict(checkpoint['model_baseline'])\n",
        "  model_train.load_state_dict(checkpoint['model_train'])\n",
        "  optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "\n",
        "  print(args); print('')\n",
        "  ckpt_details = 'Epoch: {:d}, Epoch Time: {:.3f}min, Train Length: {:.3f}, Baseline Length: {:.3f}, Test Length: {:.3f}'.format(\n",
        "          epoch_ckpt, time_ckpt/60, TSP_length_ckpt[0], TSP_length_ckpt[1], mean_tour_length_test) \n",
        "  print(ckpt_details)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXpeTyVCV6qS"
      },
      "source": [
        "### ii. Plot tour lengths vs. epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MCliZoaV9lE"
      },
      "source": [
        "clear_output()\n",
        "if LOAD:\n",
        "  plt.plot(torch.Tensor(plot_performance_train_ckpt)[:,0], torch.Tensor(plot_performance_train_ckpt)[:,1], 'r-', label=\"Train\")\n",
        "  plt.plot(torch.Tensor(plot_performance_baseline_ckpt)[:,0], torch.Tensor(plot_performance_baseline_ckpt)[:,1], 'b-', label=\"Baseline\")\n",
        "  plt.title(\"Tour length vs. Epoch\"); \n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Length')\n",
        "  plt.show()\n",
        "  print(f\"Min: {str(torch.Tensor(plot_performance_baseline_ckpt)[:,1].min().item())[:5]}\")\n",
        "  print(f\"#TSP/Epoch: {str(args.batch_per_epoch_train * args.batch_size)}\")\n",
        "else:\n",
        "  plt.plot(torch.Tensor(plot_performance_train)[:,0], torch.Tensor(plot_performance_train)[:,1], 'r-', label=\"Train\")\n",
        "  plt.plot(torch.Tensor(plot_performance_baseline)[:,0], torch.Tensor(plot_performance_baseline)[:,1], 'b-', label=\"Baseline\")\n",
        "  plt.title(\"Tour length vs. Epoch\"); \n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Length')\n",
        "  plt.show()\n",
        "  print(f\"Min: {str(torch.Tensor(plot_performance_baseline)[:,1].min().item())[:5]}\")\n",
        "  print(f\"#TSP/Epoch: {str(args.batch_per_epoch_train * args.batch_size)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMy22fojXl8u"
      },
      "source": [
        "# Plotting baseline tour length vs. epochs\n",
        "if args.node_count == 16:\n",
        "  color = \"r-\"\n",
        "elif args.node_count == 32:\n",
        "  color = \"b-\"\n",
        "elif args.node_count == 64:\n",
        "  color = \"g-\"\n",
        "elif args.node_count == 128:\n",
        "  color = \"black-\"\n",
        "\n",
        "clear_output()\n",
        "plt.plot(torch.Tensor(plot_performance_train_ckpt)[:,0], torch.Tensor(plot_performance_train_ckpt)[:,1], color, label=f\"TSP{args.node_count}\")\n",
        "plt.title(\"Baseline Tour Length vs. Training Epochs\")\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Tour Length')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dxsd_PmNX9nh"
      },
      "source": [
        "### iii. Plot the TSP tours"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cajFs41oX35M"
      },
      "source": [
        "if args.node_count == 16:\n",
        "  width = 0.5\n",
        "elif args.node_count == 32:\n",
        "  width = 0.2\n",
        "elif args.node_count == 64:\n",
        "  width = 0.05\n",
        "elif args.node_count == 128:\n",
        "  width = 0.02\n",
        "\n",
        "def plot_gnn_tsp(x_coord, x_path, plot_dist_pair=True):\n",
        "  x_coord = x_coord.detach().cpu()\n",
        "  x_path = x_path.detach().cpu()\n",
        "\n",
        "  # Compute TSP lengths\n",
        "  tsp_length = compute_tour_length(x_coord, x_path)\n",
        "\n",
        "  # Prepare variables for plotting\n",
        "  x_coord = np.array(x_coord)\n",
        "  x_path = np.array(x_path)\n",
        "  batch_size = x_coord.shape[0]\n",
        "  node_count = x_coord.shape[1]\n",
        "  graph = nx.from_numpy_matrix(np.zeros((node_count, node_count)))\n",
        "  colors = ['g'] + ['b'] * (node_count - 1) # Green for first node, blue for others\n",
        "  max_plot_count = 3**2\n",
        "  plot_count = batch_size if batch_size < max_plot_count else max_plot_count\n",
        "  rows = 1\n",
        "  cols = 3\n",
        "  f = plt.figure(figsize=(15, 5))\n",
        "\n",
        "  # Loop over TSPs and plot\n",
        "  for i in range(3):\n",
        "    x_coord_i = x_coord[i]\n",
        "    pos_i = dict(zip(range(len(x_coord_i)), x_coord_i.tolist()))\n",
        "    if plot_dist_pair: # Compute pairwise distances matrix for better visualization\n",
        "      dist_pair_i = squareform(pdist(x_coord_i, metric='euclidean')) \n",
        "      G = nx.from_numpy_matrix(dist_pair_i)\n",
        "    x_path_i = x_path[i] \n",
        "    length_tsp_i = tsp_length[i]\n",
        "    nodes_pair_tsp_i = []\n",
        "    for r in range(node_count-1):\n",
        "      nodes_pair_tsp_i.append((x_path_i[r], x_path_i[r+1]))\n",
        "    nodes_pair_tsp_i.append((x_path_i[node_count-1], x_path_i[0]))\n",
        "\n",
        "    # Plot the Concorde solution\n",
        "    subf = f.add_subplot(rows,cols,i+1)\n",
        "    nx.draw_networkx_nodes(G, pos_i, node_color=colors, node_size=50)\n",
        "    nx.draw_networkx_edges(G, pos_i, edgelist=nodes_pair_tsp_i, alpha=1, width=1, edge_color='r')\n",
        "    if plot_dist_pair:\n",
        "        nx.draw_networkx_edges(G, pos_i, alpha=0.3, width=0.5)\n",
        "    subf.set_title('Length: ' + str(length_tsp_i.item())[:5])\n",
        "\n",
        "def plot_concorde_tsp(x_coord, plot_dist_pair=True):\n",
        "  FACTOR=100\n",
        "  x_coord = x_coord.detach().cpu()*100\n",
        "\n",
        "  # Prepare variables for plotting\n",
        "  x_coord = np.array(x_coord)\n",
        "  node_count = x_coord.shape[1]\n",
        "  graph = nx.from_numpy_matrix(np.zeros((node_count, node_count)))\n",
        "  colors = ['g'] + ['b'] * (node_count - 1) # Green for first node, blue for others\n",
        "  plot_count = 3\n",
        "  rows = 1\n",
        "  cols = int(plot_count)\n",
        "  f = plt.figure(figsize=(15, 5))\n",
        "\n",
        "  # Loop over TSPs and plot\n",
        "  for i in range(plot_count):\n",
        "    x_coord_i = x_coord[i]\n",
        "    pos_i = dict(zip(range(len(x_coord_i)), x_coord_i.tolist()))\n",
        "    if plot_dist_pair: # Compute pairwise distances matrix for better visualization\n",
        "      dist_pair_i = squareform(pdist(x_coord_i, metric='euclidean')) \n",
        "      G = nx.from_numpy_matrix(dist_pair_i)\n",
        "\n",
        "    # Solve graph using Concorde\n",
        "    graph =  pd.DataFrame({'lat' : x_coord_i[:,0]}); graph['lon'] =  x_coord_i[:,1]\n",
        "    solver = TSPSolver.from_data( graph.lat, graph.lon, norm=\"EUC_2D\" )  \n",
        "    solution = solver.solve().tour\n",
        "    nodes_pair_concorde_i = []\n",
        "    for r in range(node_count-1):\n",
        "        nodes_pair_concorde_i.append((solution[r], solution[r+1]))\n",
        "    nodes_pair_concorde_i.append((solution[node_count-1], solution[0]))\n",
        "    \n",
        "    length_concorde = solver.solve().optimal_value/FACTOR\n",
        "\n",
        "    subf = f.add_subplot(rows,cols,i+1)\n",
        "    nx.draw_networkx_nodes(G, pos_i, node_color=colors, node_size=50)\n",
        "    nx.draw_networkx_edges(G, pos_i, edgelist=nodes_pair_concorde_i, alpha=1, width=1, edge_color='b') #, style='dashed'\n",
        "    if plot_dist_pair:\n",
        "      nx.draw_networkx_edges(G, pos_i, alpha=0.3, width=0.5)\n",
        "    subf.set_title('Length: ' + str(length_concorde))\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arQFHN_pYNRm"
      },
      "source": [
        "# Plotting the TSP tours generated by the model\n",
        "try:\n",
        "  sorted_nodes, _, tour_baseline, _, _, _ = model_baseline(tsp_data, deterministic=True)\n",
        "  plot_gnn_tsp(sorted_nodes, tour_baseline)\n",
        "except:\n",
        "  model_baseline = model_baseline.to(device)\n",
        "  sorted_nodes, _, tour_baseline, _, _, _ = model_baseline(tsp_data, deterministic=True)\n",
        "  plot_gnn_tsp(sorted_nodes, tour_baseline)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8-JS-hWYSMT"
      },
      "source": [
        "# Plotting the optimal TSP tours\n",
        "if INSTALL_PYCONCORDE:\n",
        "  plot_concorde_tsp(tsp_data)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}